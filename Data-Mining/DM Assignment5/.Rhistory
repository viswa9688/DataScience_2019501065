var(data_1000$open_new)
var(data_1000$high_new)
var(data_1000$low_new)
var(data_1000$close_new)
var(data_1000$volume_new)
var(data_1000$Adj.close_new)
max(data_1000$open_new)
max(data_1000$high_new)
max(data_1000$low_new)
max(data_1000$close_new)
max(data_1000$volume_new)
max(data_1000$Adj.close_new)
quantile(data_1000$open_new,0.25)
quantile(data_1000$high_new,0.25)
quantile(data_1000$low_new,0.25)
quantile(data_1000$close_new,0.25)
quantile(data_1000$volume_new,0.25)
quantile(data_1000$Adj.close_new,0.25)
mean(data_3000$open_new)
mean(data_3000$high_new)
mean(data_3000$low_new)
mean(data_3000$close_new)
mean(data_3000$volume_new)
mean(data_3000$Adj.close_new)
var(data_3000$open_new)
var(data_3000$high_new)
var(data_3000$low_new)
var(data_3000$close_new)
var(data_3000$volume_new)
var(data_3000$Adj.close_new)
max(data_3000$open_new)
max(data_3000$high_new)
max(data_3000$low_new)
max(data_3000$close_new)
max(data_3000$volume_new)
max(data_3000$Adj.close_new)
quantile(data_3000$open_new,0.25)
quantile(data_3000$high_new,0.25)
quantile(data_3000$low_new,0.25)
quantile(data_3000$close_new,0.25)
quantile(data_3000$volume_new,0.25)
quantile(data_3000$Adj.close_new,0.25)
mean(data$open_new)
mean(data$high_new)
mean(data$low_new)
mean(data$close_new)
mean(data$volume_new)
mean(data$Adj.close_new)
var(data$open_new)
var(data$high_new)
var(data$low_new)
var(data$close_new)
var(data$volume_new)
var(data$Adj.close_new)
max(data$open_new)
max(data$high_new)
max(data$low_new)
max(data$close_new)
max(data$volume_new)
max(data$Adj.close_new)
quantile(data$open_new,0.25)
quantile(data$high_new,0.25)
quantile(data$low_new,0.25)
quantile(data$close_new,0.25)
quantile(data$volume_new,0.25)
quantile(data$Adj.close_new,0.25)
# They appear to be very similar
boxplot(data$Open, data$High, data$Low, data$Adj.close, data$Close)
hist(data$Close, freq = TRUE, w = 2000)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
{
fileExt <- function(x) {
db <- grepl("\\.[^.]+\\.(gz|bz2|xz)$", x)
ans <- sub(".*\\.", "", x)
ans[db] <- sub(".*\\.([^.]+\\.)(gz|bz2|xz)$", "\\1\\2",
x[db])
ans
}
my_read_table <- function(...) {
lcc <- Sys.getlocale("LC_COLLATE")
on.exit(Sys.setlocale("LC_COLLATE", lcc))
Sys.setlocale("LC_COLLATE", "C")
read.table(...)
}
names <- c(as.character(substitute(list(...))[-1L]), list)
if (!is.null(package)) {
if (!is.character(package))
stop("'package' must be a character string or NULL")
if (FALSE) {
if (any(package %in% "base"))
warning("datasets have been moved from package 'base' to package 'datasets'")
if (any(package %in% "stats"))
warning("datasets have been moved from package 'stats' to package 'datasets'")
package[package %in% c("base", "stats")] <- "datasets"
}
}
paths <- find.package(package, lib.loc, verbose = verbose)
if (is.null(lib.loc))
paths <- c(path.package(package, TRUE), if (!length(package)) getwd(),
paths)
paths <- unique(normalizePath(paths[file.exists(paths)]))
paths <- paths[dir.exists(file.path(paths, "data"))]
dataExts <- tools:::.make_file_exts("data")
if (length(names) == 0L) {
db <- matrix(character(), nrow = 0L, ncol = 4L)
for (path in paths) {
entries <- NULL
packageName <- if (file_test("-f", file.path(path,
"DESCRIPTION")))
basename(path)
else "."
if (file_test("-f", INDEX <- file.path(path, "Meta",
"data.rds"))) {
entries <- readRDS(INDEX)
}
else {
dataDir <- file.path(path, "data")
entries <- tools::list_files_with_type(dataDir,
"data")
if (length(entries)) {
entries <- unique(tools::file_path_sans_ext(basename(entries)))
entries <- cbind(entries, "")
}
}
if (NROW(entries)) {
if (is.matrix(entries) && ncol(entries) == 2L)
db <- rbind(db, cbind(packageName, dirname(path),
entries))
else warning(gettextf("data index for package %s is invalid and will be ignored",
sQuote(packageName)), domain = NA, call. = FALSE)
}
}
colnames(db) <- c("Package", "LibPath", "Item", "Title")
footer <- if (missing(package))
paste0("Use ", sQuote(paste("data(package =", ".packages(all.available = TRUE))")),
"\n", "to list the data sets in all *available* packages.")
else NULL
y <- list(title = "Data sets", header = NULL, results = db,
footer = footer)
class(y) <- "packageIQR"
return(y)
}
paths <- file.path(paths, "data")
for (name in names) {
found <- FALSE
for (p in paths) {
tmp_env <- if (overwrite)
envir
else new.env()
if (file_test("-f", file.path(p, "Rdata.rds"))) {
rds <- readRDS(file.path(p, "Rdata.rds"))
if (name %in% names(rds)) {
found <- TRUE
if (verbose)
message(sprintf("name=%s:\t found in Rdata.rds",
name), domain = NA)
thispkg <- sub(".*/([^/]*)/data$", "\\1",
p)
thispkg <- sub("_.*$", "", thispkg)
thispkg <- paste0("package:", thispkg)
objs <- rds[[name]]
lazyLoad(file.path(p, "Rdata"), envir = tmp_env,
filter = function(x) x %in% objs)
break
}
else if (verbose)
message(sprintf("name=%s:\t NOT found in names() of Rdata.rds, i.e.,\n\t%s\n",
name, paste(names(rds), collapse = ",")),
domain = NA)
}
if (file_test("-f", file.path(p, "Rdata.zip"))) {
warning("zipped data found for package ", sQuote(basename(dirname(p))),
".\nThat is defunct, so please re-install the package.",
domain = NA)
if (file_test("-f", fp <- file.path(p, "filelist")))
files <- file.path(p, scan(fp, what = "",
quiet = TRUE))
else {
warning(gettextf("file 'filelist' is missing for directory %s",
sQuote(p)), domain = NA)
next
}
}
else {
files <- list.files(p, full.names = TRUE)
}
files <- files[grep(name, files, fixed = TRUE)]
if (length(files) > 1L) {
o <- match(fileExt(files), dataExts, nomatch = 100L)
paths0 <- dirname(files)
paths0 <- factor(paths0, levels = unique(paths0))
files <- files[order(paths0, o)]
}
if (length(files)) {
for (file in files) {
if (verbose)
message("name=", name, ":\t file= ...",
.Platform$file.sep, basename(file), "::\t",
appendLF = FALSE, domain = NA)
ext <- fileExt(file)
if (basename(file) != paste0(name, ".", ext))
found <- FALSE
else {
found <- TRUE
zfile <- file
zipname <- file.path(dirname(file), "Rdata.zip")
if (file.exists(zipname)) {
Rdatadir <- tempfile("Rdata")
dir.create(Rdatadir, showWarnings = FALSE)
topic <- basename(file)
rc <- .External(C_unzip, zipname, topic,
Rdatadir, FALSE, TRUE, FALSE, FALSE)
if (rc == 0L)
zfile <- file.path(Rdatadir, topic)
}
if (zfile != file)
on.exit(unlink(zfile))
switch(ext, R = , r = {
library("utils")
sys.source(zfile, chdir = TRUE, envir = tmp_env)
}, RData = , rdata = , rda = load(zfile,
envir = tmp_env), TXT = , txt = , tab = ,
tab.gz = , tab.bz2 = , tab.xz = , txt.gz = ,
txt.bz2 = , txt.xz = assign(name, my_read_table(zfile,
header = TRUE, as.is = FALSE), envir = tmp_env),
CSV = , csv = , csv.gz = , csv.bz2 = ,
csv.xz = assign(name, my_read_table(zfile,
header = TRUE, sep = ";", as.is = FALSE),
envir = tmp_env), found <- FALSE)
}
if (found)
break
}
if (verbose)
message(if (!found)
"*NOT* ", "found", domain = NA)
}
if (found)
break
}
if (!found) {
warning(gettextf("data set %s not found", sQuote(name)),
domain = NA)
}
else if (!overwrite) {
for (o in ls(envir = tmp_env, all.names = TRUE)) {
if (exists(o, envir = envir, inherits = FALSE))
warning(gettextf("an object named %s already exists and will not be overwritten",
sQuote(o)))
else assign(o, get(o, envir = tmp_env, inherits = FALSE),
envir = envir)
}
rm(tmp_env)
}
}
invisible(names)
}
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment4")
getwd()
train = read.csv("sonar_train.csv",header = FALSE)
test = read.csv("sonar_test.csv",header = FALSE)
summary(train)
dim(train)
summary(test)
dim(test)
library(rpart)
library(rpart.plot)
help("rpart.control")
help("rpart.plot")
x <- train[,1:60]
y <- as.factor(train[,61])
model <- rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=5))
rpart.plot(model, box.palette="RdBu", shadow.col="gray", nn=TRUE)
plot(model)
text(model)
x_test <- test[,1:60]
y_test <- as.factor(test[,61])
1 - sum(y_test == predict(model,x_test,type = "class")) / length(y_test) #0.2564103
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment4")
getwd()
train = read.csv("sonar_train.csv",header = FALSE)
test = read.csv("sonar_test.csv",header = FALSE)
summary(train)
dim(train)
summary(test)
dim(test)
library(rpart)
library(rpart.plot)
help("rpart.control")
help("rpart.plot")
x <- train[,1:60]
y <- as.factor(train[,61])
model <- rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=5))
rpart.plot(model, box.palette="RdBu", shadow.col="gray", nn=TRUE)
plot(model)
text(model)
x_test <- test[,1:60]
y_test <- as.factor(test[,61])
1 - sum(y_test == predict(model,x_test,type = "class")) / length(y_test)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment4")
getwd()
train = read.csv("sonar_train.csv",header = FALSE)
test = read.csv("sonar_test.csv",header = FALSE)
summary(train)
dim(train)
summary(test)
dim(test)
library(rpart)
library(rpart.plot)
help("rpart.control")
help("rpart.plot")
x <- train[,1:60]
y <- as.factor(train[,61])
model <- rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=5))
rpart.plot(model, box.palette="RdBu", shadow.col="gray", nn=TRUE)
x_test <- test[,1:60]
y_test <- as.factor(test[,61])
1 - sum(y_test == predict(model,x_test,type = "class")) / length(y_test)
install.packages("randomForest")
library("randomForest")
train <- read.csv("sonar_test.csv", header = FALSE)
test <- read.csv("sonar_test.csv", header = FALSE)
x_train = train[,1:60]
y_train = as.factor(train[,61])
x_test = test[,1:60]
y_test = as.factor(test[,61])
model<-randomForest(x_train, y_train)
1 - sum(y_train == predict(model, x_train)) / length(y_train)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment4")
library(class)
train <- read.csv("sonar_test.csv", header = FALSE)
test <- read.csv("sonar_test.csv", header = FALSE)
x_train = train[,1:60]
y_train = as.factor(train[,61])
x_test = test[,1:60]
y_test = as.factor(test[,61])
help("knn")
model1<-knn(x_train, x_test,y_train, k = 5)
1 - sum(y_test == model1) / length(y_test)
model2<-knn(x_train, x_test, y_train, k = 6)
1 - sum(y_test == model2) / length(y_test)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment4")
library(class)
train <- read.csv("sonar_test.csv", header = FALSE)
test <- read.csv("sonar_test.csv", header = FALSE)
x_train = train[,1:60]
y_train = as.factor(train[,61])
x_test = test[,1:60]
y_test = as.factor(test[,61])
help("knn")
model1<-knn(x_train, x_test,y_train, k = 5)
1 - sum(y_test == model1) / length(y_test)
model2<-knn(x_train, x_test, y_train, k = 6)
1 - sum(y_test == model2) / length(y_test)
data <- read.csv("sonar_test.csv", header = FALSE)
x <- data[,1:2]
plot(x, pch=19, xlab = expression(x[1]), ylab = expression(x[2]))
fit <- kmeans(x, 2)
points(fit$centers, pch = 19, col = "blue", cex = 2)
library(class)
knnfit <- knn(fit$centers, x, as.factor(c(-1, 1)))
points(x, col = 1 + 1 * as.numeric(knnfit), pch = 19)
data <- read.csv("sonar_test.csv", header = FALSE)
x <- data[,1:2]
plot(x, pch=19, xlab = expression(x[1]), ylab = expression(x[2]))
fit <- kmeans(x, 2)
points(fit$centers, pch = 19, col = "blue", cex = 2)
library(class)
knnfit <- knn(fit$centers, x, as.factor(c(-1, 1)))
points(x, col = 1 + 1 * as.numeric(knnfit), pch = 19)
# Misclassification error rate
plot(x, pch=19, xlab=expression(x[1]), ylab=expression(x[2]))
y <- data[,61]
points(x, col=2 + 2 * y, pch=19)
errorrate <- 1-sum(knnfit==y)/length(y)
errorrate
data <- read.csv("sonar_test.csv", header = FALSE)
x <- data[,1:2]
plot(x, pch=19, xlab = expression(x[1]), ylab = expression(x[2]))
fit <- kmeans(x, 2)
points(fit$centers, pch = 19, col = "blue", cex = 2)
library(class)
knnfit <- knn(fit$centers, x, as.factor(c(-1, 1)))
points(x, col = 1 + 1 * as.numeric(knnfit), pch = 19)
# Misclassification error rate
plot(x, pch=19, xlab=expression(x[1]), ylab=expression(x[2]))
y <- data[,61]
points(x, col=2 + 2 * y, pch=19)
errorrate <- 1-sum(knnfit==y)/length(y)
errorrate
data <- read.csv("sonar_test.csv", header = FALSE)
x <- data[,1:2]
plot(x, pch=19, xlab = expression(x[1]), ylab = expression(x[2]))
fit <- kmeans(x, 2)
points(fit$centers, pch = 19, col = "blue", cex = 2)
library(class)
knnfit <- knn(fit$centers, x, as.factor(c(-1, 1)))
points(x, col = 1 + 1 * as.numeric(knnfit), pch = 19)
# Misclassification error rate
plot(x, pch=19, xlab=expression(x[1]), ylab=expression(x[2]))
y <- data[,61]
points(x, col=2 + 2 * y, pch=19)
errorrate <- 1-sum(knnfit==y)/length(y)
errorrate
data <- read.csv("sonar_test.csv", header = FALSE)
x <- data[,1:2]
plot(x, pch=19, xlab = expression(x[1]), ylab = expression(x[2]))
fit <- kmeans(x, 2)
points(fit$centers, pch = 19, col = "blue", cex = 2)
library(class)
knnfit <- knn(fit$centers, x, as.factor(c(-1, 1)))
points(x, col = 1 + 1 * as.numeric(knnfit), pch = 19)
# Misclassification error rate
plot(x, pch=19, xlab=expression(x[1]), ylab=expression(x[2]))
y <- data[,61]
points(x, col=2 + 2 * y, pch=19)
errorrate <- 1-sum(knnfit==y)/length(y)
errorrate
data <- read.csv("sonar_test.csv", header = FALSE)
x <- data[,1:2]
plot(x, pch=19, xlab = expression(x[1]), ylab = expression(x[2]))
fit <- kmeans(x, 2)
points(fit$centers, pch = 19, col = "blue", cex = 2)
library(class)
knnfit <- knn(fit$centers, x, as.factor(c(-1, 1)))
points(x, col = 1 + 1 * as.numeric(knnfit), pch = 19)
# Misclassification error rate
plot(x, pch=19, xlab=expression(x[1]), ylab=expression(x[2]))
y <- data[,61]
points(x, col=2 + 2 * y, pch=19)
errorrate <- 1-sum(knnfit==y)/length(y)
errorrate
x <- data[,1:60]
fit <- kmeans(x, 2)
library(class)
knnfit <- knn(fit$centers,x,as.factor(c(-1,1)))
errorrate1 = 1 - sum(knnfit==y)/length(y)
errorrate1
x <- c(1, 2, 2.5, 3, 3.5, 4, 4.5, 5, 7, 8, 8.5, 9, 9.5, 10)
center1 <- 1
center2 <- 2
for (k in 2:10){
cluster1 <- x[abs(x-center1[k-1]) <= abs(x-center2[k-1])]
cluster2 <- x[abs(x-center1[k-1]) >  abs(x-center2[k-1])]
center1[k] <- mean(cluster1)
center2[k] <- mean(cluster2)
}
print(cluster1)
print(cluster2)
x <- c(1, 2, 2.5, 3, 3.5, 4, 4.5, 5, 7, 8, 8.5, 9, 9.5, 10)
print(kmeans(x, 2))
x1<-c(1,2)
x2<-c(5,10)
result = ((x1[1]-x2[1])^2 + (x1[2]-x2[2])^2)^0.5
print(result)
x1<-c(1,2,3,6)
x2<-c(5,10,4,12)
result = ((x1[1]-x2[1])^2 + (x1[2]-x2[2])^2 + (x1[3]-x2[3])^2 + (x1[4]-x2[4])^2)^0.5
print(result)
exams <- read.csv("spring2008exams.csv")
str(exams)
mean1 <- mean(exams$Midterm.1, na.rm = TRUE)
sd1 <- sd(exams$Midterm.1, na.rm = TRUE)
z_score <- (exams$Midterm.1 - mean1)/sd1
sort(z_score)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment5")
exams <- read.csv("spring2008exams.csv")
str(exams)
mean1 <- mean(exams$Midterm.1, na.rm = TRUE)
sd1 <- sd(exams$Midterm.1, na.rm = TRUE)
z_score <- (exams$Midterm.1 - mean1)/sd1
sort(z_score)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment5")
exams2 <- read.csv("spring2008exams.csv")
str(exams2)
mean2 <- mean(exams$Midterm.2, na.rm = TRUE)
sd2 <- sd(exams$Midterm.2, na.rm = TRUE)
z_score2 <- (exams2$Midterm.2 - mean2)/sd2
sort(z_score2)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment5")
exams <- read.csv("spring2008exams.csv")
str(exams)
q1 = quantile(exams$Midterm.2, .25, na.rm = TRUE)
q3 = quantile(exams$Midterm.2, .75, na.rm = TRUE)
iqr <- q3 - q1
iqr
exams[(exams$Midterm.2 > q3 + 1.5 * iqr), 3]
exams[(exams$Midterm.2 > q1 - 1.5 * iqr), 3]
boxplot(exams$Midterm.2, col="blue", main="Exam Scores", xlab=("Exam 2"),ylab="Exam Score")
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment5")
exams <- read.csv("spring2008exams.csv")
str(exams)
q1 = quantile(exams$Midterm.2, .25, na.rm = TRUE)
q3 = quantile(exams$Midterm.2, .75, na.rm = TRUE)
iqr <- q3 - q1
iqr
exams[(exams$Midterm.2 > q3 + 1.5 * iqr), 3]
exams[(exams$Midterm.2 > q1 - 1.5 * iqr), 3]
boxplot(exams$Midterm.2, col="blue", main="Exam Scores", xlab=("Exam 2"),ylab="Exam Score")
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment5")
exams <- read.csv("spring2008exams.csv")
model <- lm(exams$Midterm.2 ~ exams$Midterm.1)
plot(exams$Midterm.1, exams$Midterm.2, pch=19,xlab="Exam 1", ylab="Exam2",xlim=c(10,100),ylim=c(10,100))
abline(model)
sort(model$residuals)
setwd("C:\\Users\\HARIKA\\Desktop\\DataScience_2019501065\\Data-Mining\\DM Assignment5")
exams <- read.csv("spring2008exams.csv")
model <- lm(exams$Midterm.2 ~ exams$Midterm.1)
plot(exams$Midterm.1, exams$Midterm.2, pch=19,xlab="Exam 1", ylab="Exam2",xlim=c(10,100),ylim=c(10,100))
abline(model)
sort(model$residuals)
